<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<title>OpenCV: Similarity check (PNSR and SSIM) on the GPU</title>
<link href="../../opencv.ico" rel="shortcut icon" type="image/x-icon" />
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<script type="text/javascript" src="../../tutorial-utils.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
//<![CDATA[
MathJax.Hub.Config(
{
  TeX: {
      Macros: {
          matTT: [ "\\[ \\left|\\begin{array}{ccc} #1 & #2 & #3\\\\ #4 & #5 & #6\\\\ #7 & #8 & #9 \\end{array}\\right| \\]", 9],
          fork: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ \\end{array} \\right.", 4],
          forkthree: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ #5 & \\mbox{#6}\\\\ \\end{array} \\right.", 6],
          forkfour: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ #5 & \\mbox{#6}\\\\ #7 & \\mbox{#8}\\\\ \\end{array} \\right.", 8],
          vecthree: ["\\begin{bmatrix} #1\\\\ #2\\\\ #3 \\end{bmatrix}", 3],
          vecthreethree: ["\\begin{bmatrix} #1 & #2 & #3\\\\ #4 & #5 & #6\\\\ #7 & #8 & #9 \\end{bmatrix}", 9],
          cameramatrix: ["#1 = \\begin{bmatrix} f_x & 0 & c_x\\\\ 0 & f_y & c_y\\\\ 0 & 0 & 1 \\end{bmatrix}", 1],
          distcoeffs: ["(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]]) \\text{ of 4, 5, 8, 12 or 14 elements}"],
          distcoeffsfisheye: ["(k_1, k_2, k_3, k_4)"],
          hdotsfor: ["\\dots", 1],
          mathbbm: ["\\mathbb{#1}", 1],
          bordermatrix: ["\\matrix{#1}", 1]
      }
  }
}
);
//]]>
</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<!--#include virtual="/google-search.html"-->
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="../../opencv-logo-small.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">OpenCV
   &#160;<span id="projectnumber">4.6.0</span>
   </div>
   <div id="projectbrief">Open Source Computer Vision</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "../../search",false,'Search');
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../d9/df8/tutorial_root.html">OpenCV Tutorials</a></li><li class="navelem"><a class="el" href="../../da/d2c/tutorial_table_of_content_gpu.html">GPU-Accelerated Computer Vision (cuda module)</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Similarity check (PNSR and SSIM) on the GPU </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><dl class="todo"><dt><b><a class="el" href="../../dd/da0/todo.html#_todo000015">Todo:</a></b></dt><dd>update this tutorial</dd></dl>
<p><b>Next Tutorial:</b> <a class="el" href="../../d8/db9/tutorial_gpu_thrust_interop.html">Using a cv::cuda::GpuMat with thrust</a></p>
<h2>Goal </h2>
<p>In the <a class="el" href="../../d5/dc4/tutorial_video_input_psnr_ssim.html">Video Input with OpenCV and similarity measurement</a> tutorial I already presented the PSNR and SSIM methods for checking the similarity between the two images. And as you could see, the execution process takes quite some time , especially in the case of the SSIM. However, if the performance numbers of an OpenCV implementation for the CPU do not satisfy you and you happen to have an NVIDIA CUDA GPU device in your system, all is not lost. You may try to port or write your owm algorithm for the video card.</p>
<p>This tutorial will give a good grasp on how to approach coding by using the GPU module of OpenCV. As a prerequisite you should already know how to handle the core, highgui and imgproc modules. So, our main goals are:</p>
<ul>
<li>What's different compared to the CPU?</li>
<li>Create the GPU code for the PSNR and SSIM</li>
<li>Optimize the code for maximal performance</li>
</ul>
<h2>The source code </h2>
<p>You may also find the source code and the video file in the <code>samples/cpp/tutorial_code/gpu/gpu-basics-similarity/gpu-basics-similarity</code> directory of the OpenCV source library or download it from <a href="https://github.com/opencv/opencv/tree/4.x/samples/cpp/tutorial_code/gpu/gpu-basics-similarity/gpu-basics-similarity.cpp">here</a>. The full source code is quite long (due to the controlling of the application via the command line arguments and performance measurement). Therefore, to avoid cluttering up these sections with those you'll find here only the functions itself.</p>
<p>The PSNR returns a float number, that if the two inputs are similar between 30 and 50 (higher is better).</p>
<div class="fragment"><div class="line"><span class="keywordtype">double</span> getPSNR(<span class="keyword">const</span> Mat&amp; I1, <span class="keyword">const</span> Mat&amp; I2)</div><div class="line">{</div><div class="line">    Mat s1;</div><div class="line">    <a class="code" href="../../d2/de8/group__core__array.html#ga6fef31bc8c4071cbc114a758a2b79c14">absdiff</a>(I1, I2, s1);       <span class="comment">// |I1 - I2|</span></div><div class="line">    s1.convertTo(s1, <a class="code" href="../../d1/d1b/group__core__hal__interface.html#ga4a3def5d72b74bed31f5f8ab7676099c">CV_32F</a>);  <span class="comment">// cannot make a square on 8 bits</span></div><div class="line">    s1 = s1.mul(s1);           <span class="comment">// |I1 - I2|^2</span></div><div class="line"></div><div class="line">    <a class="code" href="../../dc/d84/group__core__basic.html#ga599fe92e910c027be274233eccad7beb">Scalar</a> s = <a class="code" href="../../d2/de8/group__core__array.html#ga716e10a2dd9e228e4d3c95818f106722">sum</a>(s1);         <span class="comment">// sum elements per channel</span></div><div class="line"></div><div class="line">    <span class="keywordtype">double</span> sse = s.val[0] + s.val[1] + s.val[2]; <span class="comment">// sum channels</span></div><div class="line"></div><div class="line">    <span class="keywordflow">if</span>( sse &lt;= 1e-10) <span class="comment">// for small values return zero</span></div><div class="line">        <span class="keywordflow">return</span> 0;</div><div class="line">    <span class="keywordflow">else</span></div><div class="line">    {</div><div class="line">        <span class="keywordtype">double</span>  mse =sse /(double)(I1.channels() * I1.total());</div><div class="line">        <span class="keywordtype">double</span> psnr = 10.0*<a class="code" href="../../df/dfc/group__cudev.html#ga6d7f752d82c289caa24bbb5a278ac31d">log10</a>((255*255)/mse);</div><div class="line">        <span class="keywordflow">return</span> psnr;</div><div class="line">    }</div><div class="line">}</div></div><!-- fragment --><div class="fragment"><div class="line"><span class="keywordtype">double</span> getPSNR_CUDA(<span class="keyword">const</span> Mat&amp; I1, <span class="keyword">const</span> Mat&amp; I2)</div><div class="line">{</div><div class="line">    cuda::GpuMat gI1, gI2, gs, t1,t2;</div><div class="line"></div><div class="line">    gI1.upload(I1);</div><div class="line">    gI2.upload(I2);</div><div class="line"></div><div class="line">    gI1.convertTo(t1, <a class="code" href="../../d1/d1b/group__core__hal__interface.html#ga4a3def5d72b74bed31f5f8ab7676099c">CV_32F</a>);</div><div class="line">    gI2.convertTo(t2, <a class="code" href="../../d1/d1b/group__core__hal__interface.html#ga4a3def5d72b74bed31f5f8ab7676099c">CV_32F</a>);</div><div class="line"></div><div class="line">    <a class="code" href="../../d2/de8/group__core__array.html#ga6fef31bc8c4071cbc114a758a2b79c14">cuda::absdiff</a>(t1.reshape(1), t2.reshape(1), gs);</div><div class="line">    <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(gs, gs, gs);</div><div class="line"></div><div class="line">    <a class="code" href="../../dc/d84/group__core__basic.html#ga599fe92e910c027be274233eccad7beb">Scalar</a> s = <a class="code" href="../../d2/de8/group__core__array.html#ga716e10a2dd9e228e4d3c95818f106722">cuda::sum</a>(gs);</div><div class="line">    <span class="keywordtype">double</span> sse = s.val[0] + s.val[1] + s.val[2];</div><div class="line"></div><div class="line">    <span class="keywordflow">if</span>( sse &lt;= 1e-10) <span class="comment">// for small values return zero</span></div><div class="line">        <span class="keywordflow">return</span> 0;</div><div class="line">    <span class="keywordflow">else</span></div><div class="line">    {</div><div class="line">        <span class="keywordtype">double</span>  mse =sse /(double)(gI1.channels() * I1.total());</div><div class="line">        <span class="keywordtype">double</span> psnr = 10.0*<a class="code" href="../../df/dfc/group__cudev.html#ga6d7f752d82c289caa24bbb5a278ac31d">log10</a>((255*255)/mse);</div><div class="line">        <span class="keywordflow">return</span> psnr;</div><div class="line">    }</div><div class="line">}</div></div><!-- fragment --><div class="fragment"><div class="line"><span class="keyword">struct </span>BufferPSNR                                     <span class="comment">// Optimized CUDA versions</span></div><div class="line">{   <span class="comment">// Data allocations are very expensive on CUDA. Use a buffer to solve: allocate once reuse later.</span></div><div class="line">    cuda::GpuMat gI1, gI2, gs, t1,t2;</div><div class="line"></div><div class="line">    cuda::GpuMat buf;</div><div class="line">};</div></div><!-- fragment --><div class="fragment"><div class="line"><span class="keywordtype">double</span> getPSNR_CUDA_optimized(<span class="keyword">const</span> Mat&amp; I1, <span class="keyword">const</span> Mat&amp; I2, BufferPSNR&amp; b)</div><div class="line">{</div><div class="line">    b.gI1.upload(I1);</div><div class="line">    b.gI2.upload(I2);</div><div class="line"></div><div class="line">    b.gI1.convertTo(b.t1, <a class="code" href="../../d1/d1b/group__core__hal__interface.html#ga4a3def5d72b74bed31f5f8ab7676099c">CV_32F</a>);</div><div class="line">    b.gI2.convertTo(b.t2, <a class="code" href="../../d1/d1b/group__core__hal__interface.html#ga4a3def5d72b74bed31f5f8ab7676099c">CV_32F</a>);</div><div class="line"></div><div class="line">    <a class="code" href="../../d2/de8/group__core__array.html#ga6fef31bc8c4071cbc114a758a2b79c14">cuda::absdiff</a>(b.t1.reshape(1), b.t2.reshape(1), b.gs);</div><div class="line">    <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(b.gs, b.gs, b.gs);</div><div class="line"></div><div class="line">    <span class="keywordtype">double</span> sse = <a class="code" href="../../d2/de8/group__core__array.html#ga716e10a2dd9e228e4d3c95818f106722">cuda::sum</a>(b.gs, b.buf)[0];</div><div class="line"></div><div class="line">    <span class="keywordflow">if</span>( sse &lt;= 1e-10) <span class="comment">// for small values return zero</span></div><div class="line">        <span class="keywordflow">return</span> 0;</div><div class="line">    <span class="keywordflow">else</span></div><div class="line">    {</div><div class="line">        <span class="keywordtype">double</span> mse = sse /(double)(I1.channels() * I1.total());</div><div class="line">        <span class="keywordtype">double</span> psnr = 10.0*<a class="code" href="../../df/dfc/group__cudev.html#ga6d7f752d82c289caa24bbb5a278ac31d">log10</a>((255*255)/mse);</div><div class="line">        <span class="keywordflow">return</span> psnr;</div><div class="line">    }</div><div class="line">}</div></div><!-- fragment --><p> The SSIM returns the MSSIM of the images. This is too a floating point number between zero and one (higher is better), however we have one for each channel. Therefore, we return a <em>Scalar</em> OpenCV data structure:</p>
<div class="fragment"><div class="line"><a class="code" href="../../dc/d84/group__core__basic.html#ga599fe92e910c027be274233eccad7beb">Scalar</a> getMSSIM( <span class="keyword">const</span> Mat&amp; i1, <span class="keyword">const</span> Mat&amp; i2)</div><div class="line">{</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">double</span> C1 = 6.5025, C2 = 58.5225;</div><div class="line">    <span class="comment">/***************************** INITS **********************************/</span></div><div class="line">    <span class="keywordtype">int</span> d     = <a class="code" href="../../d1/d1b/group__core__hal__interface.html#ga4a3def5d72b74bed31f5f8ab7676099c">CV_32F</a>;</div><div class="line"></div><div class="line">    Mat I1, I2;</div><div class="line">    i1.convertTo(I1, d);           <span class="comment">// cannot calculate on one byte large values</span></div><div class="line">    i2.convertTo(I2, d);</div><div class="line"></div><div class="line">    Mat I2_2   = I2.mul(I2);        <span class="comment">// I2^2</span></div><div class="line">    Mat I1_2   = I1.mul(I1);        <span class="comment">// I1^2</span></div><div class="line">    Mat I1_I2  = I1.mul(I2);        <span class="comment">// I1 * I2</span></div><div class="line"></div><div class="line">    <span class="comment">/*************************** END INITS **********************************/</span></div><div class="line"></div><div class="line">    Mat mu1, mu2;   <span class="comment">// PRELIMINARY COMPUTING</span></div><div class="line">    <a class="code" href="../../d4/d86/group__imgproc__filter.html#gaabe8c836e97159a9193fb0b11ac52cf1">GaussianBlur</a>(I1, mu1, <a class="code" href="../../dc/d84/group__core__basic.html#ga346f563897249351a34549137c8532a0">Size</a>(11, 11), 1.5);</div><div class="line">    <a class="code" href="../../d4/d86/group__imgproc__filter.html#gaabe8c836e97159a9193fb0b11ac52cf1">GaussianBlur</a>(I2, mu2, <a class="code" href="../../dc/d84/group__core__basic.html#ga346f563897249351a34549137c8532a0">Size</a>(11, 11), 1.5);</div><div class="line"></div><div class="line">    Mat mu1_2   =   mu1.mul(mu1);</div><div class="line">    Mat mu2_2   =   mu2.mul(mu2);</div><div class="line">    Mat mu1_mu2 =   mu1.mul(mu2);</div><div class="line"></div><div class="line">    Mat sigma1_2, sigma2_2, sigma12;</div><div class="line"></div><div class="line">    <a class="code" href="../../d4/d86/group__imgproc__filter.html#gaabe8c836e97159a9193fb0b11ac52cf1">GaussianBlur</a>(I1_2, sigma1_2, <a class="code" href="../../dc/d84/group__core__basic.html#ga346f563897249351a34549137c8532a0">Size</a>(11, 11), 1.5);</div><div class="line">    sigma1_2 -= mu1_2;</div><div class="line"></div><div class="line">    <a class="code" href="../../d4/d86/group__imgproc__filter.html#gaabe8c836e97159a9193fb0b11ac52cf1">GaussianBlur</a>(I2_2, sigma2_2, <a class="code" href="../../dc/d84/group__core__basic.html#ga346f563897249351a34549137c8532a0">Size</a>(11, 11), 1.5);</div><div class="line">    sigma2_2 -= mu2_2;</div><div class="line"></div><div class="line">    <a class="code" href="../../d4/d86/group__imgproc__filter.html#gaabe8c836e97159a9193fb0b11ac52cf1">GaussianBlur</a>(I1_I2, sigma12, <a class="code" href="../../dc/d84/group__core__basic.html#ga346f563897249351a34549137c8532a0">Size</a>(11, 11), 1.5);</div><div class="line">    sigma12 -= mu1_mu2;</div><div class="line"></div><div class="line">    Mat t1, t2, t3;</div><div class="line"></div><div class="line">    t1 = 2 * mu1_mu2 + C1;</div><div class="line">    t2 = 2 * sigma12 + C2;</div><div class="line">    t3 = t1.mul(t2);              <span class="comment">// t3 = ((2*mu1_mu2 + C1).*(2*sigma12 + C2))</span></div><div class="line"></div><div class="line">    t1 = mu1_2 + mu2_2 + C1;</div><div class="line">    t2 = sigma1_2 + sigma2_2 + C2;</div><div class="line">    t1 = t1.mul(t2);               <span class="comment">// t1 =((mu1_2 + mu2_2 + C1).*(sigma1_2 + sigma2_2 + C2))</span></div><div class="line"></div><div class="line">    Mat ssim_map;</div><div class="line">    <a class="code" href="../../d2/de8/group__core__array.html#ga6db555d30115642fedae0cda05604874">divide</a>(t3, t1, ssim_map);      <span class="comment">// ssim_map =  t3./t1;</span></div><div class="line"></div><div class="line">    <a class="code" href="../../dc/d84/group__core__basic.html#ga599fe92e910c027be274233eccad7beb">Scalar</a> mssim = <a class="code" href="../../d2/de8/group__core__array.html#ga191389f8a0e58180bb13a727782cd461">mean</a>( ssim_map ); <span class="comment">// mssim = average of ssim map</span></div><div class="line">    <span class="keywordflow">return</span> mssim;</div><div class="line">}</div></div><!-- fragment --><div class="fragment"><div class="line"><a class="code" href="../../dc/d84/group__core__basic.html#ga599fe92e910c027be274233eccad7beb">Scalar</a> getMSSIM_CUDA( <span class="keyword">const</span> Mat&amp; i1, <span class="keyword">const</span> Mat&amp; i2)</div><div class="line">{</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">float</span> C1 = 6.5025f, C2 = 58.5225f;</div><div class="line">    <span class="comment">/***************************** INITS **********************************/</span></div><div class="line">    cuda::GpuMat gI1, gI2, gs1, tmp1,tmp2;</div><div class="line"></div><div class="line">    gI1.upload(i1);</div><div class="line">    gI2.upload(i2);</div><div class="line"></div><div class="line">    gI1.convertTo(tmp1, <a class="code" href="../../d1/d1b/group__core__hal__interface.html#gac0f2281e91c4e610de4f450eb0a39993">CV_MAKE_TYPE</a>(<a class="code" href="../../d1/d1b/group__core__hal__interface.html#ga4a3def5d72b74bed31f5f8ab7676099c">CV_32F</a>, gI1.channels()));</div><div class="line">    gI2.convertTo(tmp2, <a class="code" href="../../d1/d1b/group__core__hal__interface.html#gac0f2281e91c4e610de4f450eb0a39993">CV_MAKE_TYPE</a>(<a class="code" href="../../d1/d1b/group__core__hal__interface.html#ga4a3def5d72b74bed31f5f8ab7676099c">CV_32F</a>, gI2.channels()));</div><div class="line"></div><div class="line">    vector&lt;cuda::GpuMat&gt; vI1, vI2;</div><div class="line">    <a class="code" href="../../d2/de8/group__core__array.html#ga0547c7fed86152d7e9d0096029c8518a">cuda::split</a>(tmp1, vI1);</div><div class="line">    <a class="code" href="../../d2/de8/group__core__array.html#ga0547c7fed86152d7e9d0096029c8518a">cuda::split</a>(tmp2, vI2);</div><div class="line">    <a class="code" href="../../dc/d84/group__core__basic.html#ga599fe92e910c027be274233eccad7beb">Scalar</a> mssim;</div><div class="line"></div><div class="line">    Ptr&lt;cuda::Filter&gt; gauss = <a class="code" href="../../dc/d66/group__cudafilters.html#gaa4df286369114cfd4b144ae211f6a6c8">cuda::createGaussianFilter</a>(vI2[0].type(), -1, <a class="code" href="../../dc/d84/group__core__basic.html#ga346f563897249351a34549137c8532a0">Size</a>(11, 11), 1.5);</div><div class="line"></div><div class="line">    <span class="keywordflow">for</span>( <span class="keywordtype">int</span> i = 0; i &lt; gI1.channels(); ++i )</div><div class="line">    {</div><div class="line">        cuda::GpuMat I2_2, I1_2, I1_I2;</div><div class="line"></div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(vI2[i], vI2[i], I2_2);        <span class="comment">// I2^2</span></div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(vI1[i], vI1[i], I1_2);        <span class="comment">// I1^2</span></div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(vI1[i], vI2[i], I1_I2);       <span class="comment">// I1 * I2</span></div><div class="line"></div><div class="line">        <span class="comment">/*************************** END INITS **********************************/</span></div><div class="line">        cuda::GpuMat mu1, mu2;   <span class="comment">// PRELIMINARY COMPUTING</span></div><div class="line">        gauss-&gt;apply(vI1[i], mu1);</div><div class="line">        gauss-&gt;apply(vI2[i], mu2);</div><div class="line"></div><div class="line">        cuda::GpuMat mu1_2, mu2_2, mu1_mu2;</div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(mu1, mu1, mu1_2);</div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(mu2, mu2, mu2_2);</div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(mu1, mu2, mu1_mu2);</div><div class="line"></div><div class="line">        cuda::GpuMat sigma1_2, sigma2_2, sigma12;</div><div class="line"></div><div class="line">        gauss-&gt;apply(I1_2, sigma1_2);</div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#gaa0f00d98b4b5edeaeb7b8333b2de353b">cuda::subtract</a>(sigma1_2, mu1_2, sigma1_2); <span class="comment">// sigma1_2 -= mu1_2;</span></div><div class="line"></div><div class="line">        gauss-&gt;apply(I2_2, sigma2_2);</div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#gaa0f00d98b4b5edeaeb7b8333b2de353b">cuda::subtract</a>(sigma2_2, mu2_2, sigma2_2); <span class="comment">// sigma2_2 -= mu2_2;</span></div><div class="line"></div><div class="line">        gauss-&gt;apply(I1_I2, sigma12);</div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#gaa0f00d98b4b5edeaeb7b8333b2de353b">cuda::subtract</a>(sigma12, mu1_mu2, sigma12); <span class="comment">// sigma12 -= mu1_mu2;</span></div><div class="line"></div><div class="line">        cuda::GpuMat t1, t2, t3;</div><div class="line"></div><div class="line">        mu1_mu2.convertTo(t1, -1, 2, C1); <span class="comment">// t1 = 2 * mu1_mu2 + C1;</span></div><div class="line">        sigma12.convertTo(t2, -1, 2, C2); <span class="comment">// t2 = 2 * sigma12 + C2;</span></div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(t1, t2, t3);        <span class="comment">// t3 = ((2*mu1_mu2 + C1).*(2*sigma12 + C2))</span></div><div class="line"></div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#gafafb2513349db3bcff51f54ee5592a19">cuda::addWeighted</a>(mu1_2, 1.0, mu2_2, 1.0, C1, t1);       <span class="comment">// t1 = mu1_2 + mu2_2 + C1;</span></div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#gafafb2513349db3bcff51f54ee5592a19">cuda::addWeighted</a>(sigma1_2, 1.0, sigma2_2, 1.0, C2, t2); <span class="comment">// t2 = sigma1_2 + sigma2_2 + C2;</span></div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(t1, t2, t1);                              <span class="comment">// t1 =((mu1_2 + mu2_2 + C1).*(sigma1_2 + sigma2_2 + C2))</span></div><div class="line"></div><div class="line">        cuda::GpuMat ssim_map;</div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga6db555d30115642fedae0cda05604874">cuda::divide</a>(t3, t1, ssim_map);      <span class="comment">// ssim_map =  t3./t1;</span></div><div class="line"></div><div class="line">        <a class="code" href="../../dc/d84/group__core__basic.html#ga599fe92e910c027be274233eccad7beb">Scalar</a> s = <a class="code" href="../../d2/de8/group__core__array.html#ga716e10a2dd9e228e4d3c95818f106722">cuda::sum</a>(ssim_map);</div><div class="line">        mssim.val[i] = s.val[0] / (ssim_map.rows * ssim_map.cols);</div><div class="line"></div><div class="line">    }</div><div class="line">    <span class="keywordflow">return</span> mssim;</div><div class="line">}</div></div><!-- fragment --><div class="fragment"><div class="line"><span class="keyword">struct </span>BufferMSSIM                                     <span class="comment">// Optimized CUDA versions</span></div><div class="line">{   <span class="comment">// Data allocations are very expensive on CUDA. Use a buffer to solve: allocate once reuse later.</span></div><div class="line">    cuda::GpuMat gI1, gI2, gs, t1,t2;</div><div class="line"></div><div class="line">    cuda::GpuMat I1_2, I2_2, I1_I2;</div><div class="line">    vector&lt;cuda::GpuMat&gt; vI1, vI2;</div><div class="line"></div><div class="line">    cuda::GpuMat mu1, mu2;</div><div class="line">    cuda::GpuMat mu1_2, mu2_2, mu1_mu2;</div><div class="line"></div><div class="line">    cuda::GpuMat sigma1_2, sigma2_2, sigma12;</div><div class="line">    cuda::GpuMat t3;</div><div class="line"></div><div class="line">    cuda::GpuMat ssim_map;</div><div class="line"></div><div class="line">    cuda::GpuMat buf;</div><div class="line">};</div></div><!-- fragment --><div class="fragment"><div class="line"><a class="code" href="../../dc/d84/group__core__basic.html#ga599fe92e910c027be274233eccad7beb">Scalar</a> getMSSIM_CUDA_optimized( <span class="keyword">const</span> Mat&amp; i1, <span class="keyword">const</span> Mat&amp; i2, BufferMSSIM&amp; b)</div><div class="line">{</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">float</span> C1 = 6.5025f, C2 = 58.5225f;</div><div class="line">    <span class="comment">/***************************** INITS **********************************/</span></div><div class="line"></div><div class="line">    b.gI1.upload(i1);</div><div class="line">    b.gI2.upload(i2);</div><div class="line"></div><div class="line">    cuda::Stream stream;</div><div class="line"></div><div class="line">    b.gI1.convertTo(b.t1, <a class="code" href="../../d1/d1b/group__core__hal__interface.html#ga4a3def5d72b74bed31f5f8ab7676099c">CV_32F</a>, stream);</div><div class="line">    b.gI2.convertTo(b.t2, <a class="code" href="../../d1/d1b/group__core__hal__interface.html#ga4a3def5d72b74bed31f5f8ab7676099c">CV_32F</a>, stream);</div><div class="line"></div><div class="line">    <a class="code" href="../../d2/de8/group__core__array.html#ga0547c7fed86152d7e9d0096029c8518a">cuda::split</a>(b.t1, b.vI1, stream);</div><div class="line">    <a class="code" href="../../d2/de8/group__core__array.html#ga0547c7fed86152d7e9d0096029c8518a">cuda::split</a>(b.t2, b.vI2, stream);</div><div class="line">    <a class="code" href="../../dc/d84/group__core__basic.html#ga599fe92e910c027be274233eccad7beb">Scalar</a> mssim;</div><div class="line"></div><div class="line">    Ptr&lt;cuda::Filter&gt; gauss = <a class="code" href="../../dc/d66/group__cudafilters.html#gaa4df286369114cfd4b144ae211f6a6c8">cuda::createGaussianFilter</a>(b.vI1[0].type(), -1, <a class="code" href="../../dc/d84/group__core__basic.html#ga346f563897249351a34549137c8532a0">Size</a>(11, 11), 1.5);</div><div class="line"></div><div class="line">    <span class="keywordflow">for</span>( <span class="keywordtype">int</span> i = 0; i &lt; b.gI1.channels(); ++i )</div><div class="line">    {</div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(b.vI2[i], b.vI2[i], b.I2_2, 1, -1, stream);        <span class="comment">// I2^2</span></div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(b.vI1[i], b.vI1[i], b.I1_2, 1, -1, stream);        <span class="comment">// I1^2</span></div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(b.vI1[i], b.vI2[i], b.I1_I2, 1, -1, stream);       <span class="comment">// I1 * I2</span></div><div class="line"></div><div class="line">        gauss-&gt;apply(b.vI1[i], b.mu1, stream);</div><div class="line">        gauss-&gt;apply(b.vI2[i], b.mu2, stream);</div><div class="line"></div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(b.mu1, b.mu1, b.mu1_2, 1, -1, stream);</div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(b.mu2, b.mu2, b.mu2_2, 1, -1, stream);</div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(b.mu1, b.mu2, b.mu1_mu2, 1, -1, stream);</div><div class="line"></div><div class="line">        gauss-&gt;apply(b.I1_2, b.sigma1_2, stream);</div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#gaa0f00d98b4b5edeaeb7b8333b2de353b">cuda::subtract</a>(b.sigma1_2, b.mu1_2, b.sigma1_2, cuda::GpuMat(), -1, stream);</div><div class="line">        <span class="comment">//b.sigma1_2 -= b.mu1_2;  - This would result in an extra data transfer operation</span></div><div class="line"></div><div class="line">        gauss-&gt;apply(b.I2_2, b.sigma2_2, stream);</div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#gaa0f00d98b4b5edeaeb7b8333b2de353b">cuda::subtract</a>(b.sigma2_2, b.mu2_2, b.sigma2_2, cuda::GpuMat(), -1, stream);</div><div class="line">        <span class="comment">//b.sigma2_2 -= b.mu2_2;</span></div><div class="line"></div><div class="line">        gauss-&gt;apply(b.I1_I2, b.sigma12, stream);</div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#gaa0f00d98b4b5edeaeb7b8333b2de353b">cuda::subtract</a>(b.sigma12, b.mu1_mu2, b.sigma12, cuda::GpuMat(), -1, stream);</div><div class="line">        <span class="comment">//b.sigma12 -= b.mu1_mu2;</span></div><div class="line"></div><div class="line">        <span class="comment">//here too it would be an extra data transfer due to call of operator*(Scalar, Mat)</span></div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(b.mu1_mu2, 2, b.t1, 1, -1, stream); <span class="comment">//b.t1 = 2 * b.mu1_mu2 + C1;</span></div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga10ac1bfb180e2cfda1701d06c24fdbd6">cuda::add</a>(b.t1, C1, b.t1, cuda::GpuMat(), -1, stream);</div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(b.sigma12, 2, b.t2, 1, -1, stream); <span class="comment">//b.t2 = 2 * b.sigma12 + C2;</span></div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga10ac1bfb180e2cfda1701d06c24fdbd6">cuda::add</a>(b.t2, C2, b.t2, cuda::GpuMat(), -12, stream);</div><div class="line"></div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(b.t1, b.t2, b.t3, 1, -1, stream);     <span class="comment">// t3 = ((2*mu1_mu2 + C1).*(2*sigma12 + C2))</span></div><div class="line"></div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga10ac1bfb180e2cfda1701d06c24fdbd6">cuda::add</a>(b.mu1_2, b.mu2_2, b.t1, cuda::GpuMat(), -1, stream);</div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga10ac1bfb180e2cfda1701d06c24fdbd6">cuda::add</a>(b.t1, C1, b.t1, cuda::GpuMat(), -1, stream);</div><div class="line"></div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga10ac1bfb180e2cfda1701d06c24fdbd6">cuda::add</a>(b.sigma1_2, b.sigma2_2, b.t2, cuda::GpuMat(), -1, stream);</div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga10ac1bfb180e2cfda1701d06c24fdbd6">cuda::add</a>(b.t2, C2, b.t2, cuda::GpuMat(), -1, stream);</div><div class="line"></div><div class="line"></div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">cuda::multiply</a>(b.t1, b.t2, b.t1, 1, -1, stream);     <span class="comment">// t1 =((mu1_2 + mu2_2 + C1).*(sigma1_2 + sigma2_2 + C2))</span></div><div class="line">        <a class="code" href="../../d2/de8/group__core__array.html#ga6db555d30115642fedae0cda05604874">cuda::divide</a>(b.t3, b.t1, b.ssim_map, 1, -1, stream);      <span class="comment">// ssim_map =  t3./t1;</span></div><div class="line"></div><div class="line">        stream.waitForCompletion();</div><div class="line"></div><div class="line">        <a class="code" href="../../dc/d84/group__core__basic.html#ga599fe92e910c027be274233eccad7beb">Scalar</a> s = <a class="code" href="../../d2/de8/group__core__array.html#ga716e10a2dd9e228e4d3c95818f106722">cuda::sum</a>(b.ssim_map, b.buf);</div><div class="line">        mssim.val[i] = s.val[0] / (b.ssim_map.rows * b.ssim_map.cols);</div><div class="line"></div><div class="line">    }</div><div class="line">    <span class="keywordflow">return</span> mssim;</div><div class="line">}</div></div><!-- fragment --> <h2>How to do it? - The GPU </h2>
<p>As see above, we have three types of functions for each operation. One for the CPU and two for the GPU. The reason I made two for the GPU is too illustrate that often simple porting your CPU to GPU will actually make it slower. If you want some performance gain you will need to remember a few rules, for which I will go into detail later on.</p>
<p>The development of the GPU module was made so that it resembles as much as possible its CPU counterpart. This makes the porting process easier. The first thing you need to do before writing any code is to link the GPU module to your project, and include the header file for the module. All the functions and data structures of the GPU are in a <em>gpu</em> sub namespace of the <em>cv</em> namespace. You may add this to the default one via the <em>use namespace</em> keyword, or mark it everywhere explicitly via the cv:: to avoid confusion. I'll do the later. </p><div class="fragment"><div class="line"><span class="preprocessor">#include &lt;opencv2/gpu.hpp&gt;</span>        <span class="comment">// GPU structures and methods</span></div></div><!-- fragment --><p>GPU stands for "graphics processing unit". It was originally built to render graphical scenes. These scenes somehow build on a lot of data. Nevertheless, these aren't all dependent one from another in a sequential way and as it is possible a parallel processing of them. Due to this a GPU will contain multiple smaller processing units. These aren't the state of the art processors and on a one on one test with a CPU it will fall behind. However, its strength lies in its numbers. In the last years there has been an increasing trend to harvest these massive parallel powers of the GPU in non-graphical scenes; rendering as well. This gave birth to the general-purpose computation on graphics processing units (GPGPU).</p>
<p>The GPU has its own memory. When you read data from the hard drive with OpenCV into a <em>Mat</em> object that takes place in your systems memory. The CPU works somehow directly on this (via its cache), however the GPU cannot. It has to transfer the information required for calculations from the system memory to its own. This is done via an upload process and is time consuming. In the end the result will have to be downloaded back to your system memory for your CPU to see and use it. Porting small functions to GPU is not recommended as the upload/download time will be larger than the amount you gain by a parallel execution.</p>
<p>Mat objects are stored only in the system memory (or the CPU cache). For getting an OpenCV matrix to the GPU you'll need to use its GPU counterpart <a class="el" href="../../d0/d60/classcv_1_1cuda_1_1GpuMat.html">cv::cuda::GpuMat</a>. It works similar to the Mat with a 2D only limitation and no reference returning for its functions (cannot mix GPU references with CPU ones). To upload a Mat object to the GPU you need to call the upload function after creating an instance of the class. To download you may use simple assignment to a Mat object or use the download function. </p><div class="fragment"><div class="line">Mat I1;         <span class="comment">// Main memory item - read image into with imread for example</span></div><div class="line">gpu::GpuMat gI; <span class="comment">// GPU matrix - for now empty</span></div><div class="line">gI1.upload(I1); <span class="comment">// Upload a data from the system memory to the GPU memory</span></div><div class="line"></div><div class="line">I1 = gI1;       <span class="comment">// Download, gI1.download(I1) will work too</span></div></div><!-- fragment --><p> Once you have your data up in the GPU memory you may call GPU enabled functions of OpenCV. Most of the functions keep the same name just as on the CPU, with the difference that they only accept <em>GpuMat</em> inputs.</p>
<p>Another thing to keep in mind is that not for all channel numbers you can make efficient algorithms on the GPU. Generally, I found that the input images for the GPU images need to be either one or four channel ones and one of the char or float type for the item sizes. No double support on the GPU, sorry. Passing other types of objects for some functions will result in an exception throw, and an error message on the error output. The documentation details in most of the places the types accepted for the inputs. If you have three channel images as an input you can do two things: either add a new channel (and use char elements) or split up the image and call the function for each image. The first one isn't really recommended as this wastes memory.</p>
<p>For some functions, where the position of the elements (neighbor items) doesn't matter, the quick solution is to reshape it into a single channel image. This is the case for the PSNR implementation where for the <em>absdiff</em> method the value of the neighbors is not important. However, for the <em>GaussianBlur</em> this isn't an option and such need to use the split method for the SSIM. With this knowledge you can make a GPU viable code (like mine GPU one) and run it. You'll be surprised to see that it might turn out slower than your CPU implementation.</p>
<h2>Optimization </h2>
<p>The reason for this is that you're throwing out on the window the price for memory allocation and data transfer. And on the GPU this is damn high. Another possibility for optimization is to introduce asynchronous OpenCV GPU calls too with the help of the <a class="el" href="../../d9/df3/classcv_1_1cuda_1_1Stream.html">cv::cuda::Stream</a>.</p>
<ol type="1">
<li>Memory allocation on the GPU is considerable. Therefore, if it’s possible allocate new memory as few times as possible. If you create a function what you intend to call multiple times it is a good idea to allocate any local parameters for the function only once, during the first call. To do this you create a data structure containing all the local variables you will use. For instance in case of the PSNR these are: <div class="fragment"><div class="line"><span class="keyword">struct </span>BufferPSNR                                     <span class="comment">// Optimized GPU versions</span></div><div class="line">  {   <span class="comment">// Data allocations are very expensive on GPU. Use a buffer to solve: allocate once reuse later.</span></div><div class="line">  gpu::GpuMat gI1, gI2, gs, t1,t2;</div><div class="line"></div><div class="line">  gpu::GpuMat buf;</div><div class="line">};</div></div><!-- fragment --> Then create an instance of this in the main program: <div class="fragment"><div class="line">BufferPSNR bufferPSNR;</div></div><!-- fragment --> And finally pass this to the function each time you call it: <div class="fragment"><div class="line"><span class="keywordtype">double</span> getPSNR_GPU_optimized(<span class="keyword">const</span> Mat&amp; I1, <span class="keyword">const</span> Mat&amp; I2, BufferPSNR&amp; b)</div></div><!-- fragment --> Now you access these local parameters as: <em>b.gI1</em>, <em>b.buf</em> and so on. The GpuMat will only reallocate itself on a new call if the new matrix size is different from the previous one.</li>
<li>Avoid unnecessary function data transfers. Any small data transfer will be significant once you go to the GPU. Therefore, if possible, make all calculations in-place (in other words do not create new memory objects - for reasons explained at the previous point). For example, although expressing arithmetical operations may be easier to express in one line formulas, it will be slower. In case of the SSIM at one point I need to calculate: <div class="fragment"><div class="line">b.t1 = 2 * b.mu1_mu2 + C1;</div></div><!-- fragment --> Although the upper call will succeed, observe that there is a hidden data transfer present. Before it makes the addition it needs to store somewhere the multiplication. Therefore, it will create a local matrix in the background, add to that the <em>C1</em> value and finally assign that to <em>t1</em>. To avoid this we use the gpu functions, instead of the arithmetic operators: <div class="fragment"><div class="line"><a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">gpu::multiply</a>(b.mu1_mu2, 2, b.t1); <span class="comment">//b.t1 = 2 * b.mu1_mu2 + C1;</span></div><div class="line"><a class="code" href="../../d2/de8/group__core__array.html#ga10ac1bfb180e2cfda1701d06c24fdbd6">gpu::add</a>(b.t1, C1, b.t1);</div></div><!-- fragment --></li>
<li>Use asynchronous calls (the <a class="el" href="../../d9/df3/classcv_1_1cuda_1_1Stream.html">cv::cuda::Stream</a> ). By default whenever you call a GPU function it will wait for the call to finish and return with the result afterwards. However, it is possible to make asynchronous calls, meaning it will call for the operation execution, making the costly data allocations for the algorithm and return back right away. Now you can call another function, if you wish. For the MSSIM this is a small optimization point. In our default implementation we split up the image into channels and call them for each channel the GPU functions. A small degree of parallelization is possible with the stream. By using a stream we can make the data allocation, upload operations while the GPU is already executing a given method. For example, we need to upload two images. We queue these one after another and call the function that processes it. The functions will wait for the upload to finish, however while this happens it makes the output buffer allocations for the function to be executed next. <div class="fragment"><div class="line">gpu::Stream stream;</div><div class="line"></div><div class="line">stream.enqueueConvert(b.gI1, b.t1, <a class="code" href="../../d1/d1b/group__core__hal__interface.html#ga4a3def5d72b74bed31f5f8ab7676099c">CV_32F</a>);    <span class="comment">// Upload</span></div><div class="line"></div><div class="line"><a class="code" href="../../d2/de8/group__core__array.html#ga0547c7fed86152d7e9d0096029c8518a">gpu::split</a>(b.t1, b.vI1, stream);              <span class="comment">// Methods (pass the stream as final parameter).</span></div><div class="line"><a class="code" href="../../d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f">gpu::multiply</a>(b.vI1[i], b.vI1[i], b.I1_2, stream);        <span class="comment">// I1^2</span></div></div><!-- fragment --></li>
</ol>
<h2>Result and conclusion </h2>
<p>On an Intel P8700 laptop CPU paired with a low end NVIDIA GT220M, here are the performance numbers: </p><div class="fragment"><div class="line">Time of PSNR CPU (averaged for 10 runs): 41.4122 milliseconds. With result of: 19.2506</div><div class="line">Time of PSNR GPU (averaged for 10 runs): 158.977 milliseconds. With result of: 19.2506</div><div class="line">Initial call GPU optimized:              31.3418 milliseconds. With result of: 19.2506</div><div class="line">Time of PSNR GPU OPTIMIZED ( / 10 runs): 24.8171 milliseconds. With result of: 19.2506</div><div class="line"></div><div class="line">Time of MSSIM CPU (averaged for 10 runs): 484.343 milliseconds. With result of B0.890964 G0.903845 R0.936934</div><div class="line">Time of MSSIM GPU (averaged for 10 runs): 745.105 milliseconds. With result of B0.89922 G0.909051 R0.968223</div><div class="line">Time of MSSIM GPU Initial Call            357.746 milliseconds. With result of B0.890964 G0.903845 R0.936934</div><div class="line">Time of MSSIM GPU OPTIMIZED ( / 10 runs): 203.091 milliseconds. With result of B0.890964 G0.903845 R0.936934</div></div><!-- fragment --><p> In both cases we managed a performance increase of almost 100% compared to the CPU implementation. It may be just the improvement needed for your application to work. You may observe a runtime instance of this on the <a href="https://www.youtube.com/watch?v=3_ESXmFlnvY">YouTube here</a>.</p>
<div align='center'><iframe title='Video' width='560' height='349' src='https://www.youtube.com/embed/3_ESXmFlnvY?rel=0' frameborder='0' align='middle' allowfullscreen></iframe></div> </div></div><!-- contents -->
<!-- HTML footer for doxygen 1.8.6-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Sun Jun 5 2022 16:19:51 for OpenCV by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="../../doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
<script type="text/javascript">
//<![CDATA[
addTutorialsButtons();
//]]>
</script>
</body>
</html>
